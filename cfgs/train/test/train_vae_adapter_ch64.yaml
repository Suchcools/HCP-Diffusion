_base_:
  - cfgs/train/test/base_dataset.yaml
  - cfgs/train/test/train_base.yaml
  - cfgs/train/test/tuning_base.yaml

train:
  train_steps: 20000
  gradient_accumulation_steps: 1
  save_step: 1000

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    betas: [0.95, 0.999]
    eps: 1e-6
    weight_decay: 0.001
  scale_lr: false
  scheduler:
      name: 'constant_with_warmup'
      num_warmup_steps: 50
      num_training_steps: 20000

model:
  pretrained_model_name_or_path: 'Lykon/DreamShaper'
  vae_channel: 64
  clip_skip: 1

dataset_dir: data/laion_pop'

vae: 
  config: vae/vaegan_ch64.yaml
  checkpoint: vae/ckpt/ch64_step=29999-model.ckpt

unet:
  - # group1
    lr: 2e-5 # Learning rates for all layers in this group
    layers: # Layers to train
      # Train all layers
      - ''

plugin_unet:
  InputAdapter:
    _target_: hcpdiff.models.adapter.InputAdapterPatch
    _partial_: True
    lr: 2e-5
    vae_channel: 64
    layers:
      - 'conv_in'
  OutputAdapter:
    _target_: hcpdiff.models.adapter.OutputAdapterPatch
    _partial_: True
    lr: 2e-5
    vae_channel: 64
    layers:
      - 'conv_out'

data:
  dataset1:
    batch_size: 200
    cache_latents: True

    # # 定义一个所有数据源通用的图像变换，具体细节参考 torchvision.transforms
    # image_transforms:
    #   _target_: torchvision.transforms.Compose # "_target_" for hydra.utils.instantiate
    #   transforms:
    #     - _target_: torchvision.transforms.ToTensor
    #     - _target_: hcpdiff.data.utils.ResizeAndPad
    #       _args_: [[512,512]]
    
    source:
      data_source1:
        img_root: ${dataset_dir}
        prompt_template: 'prompt_tuning_template/caption.txt'
        caption_file: ${dataset_dir}  # path to image captions (file_words)

    # support images with any size, not recommended for anime training
    # bucket:
    #   _target_: hcpdiff.data.bucket.RatioBucket.from_files # aspect ratio bucket
    #   target_area: ${times:512,512}
    #   num_bucket: 5

    # all images must have the same size, such as 512x704
    bucket:
      _target_: hcpdiff.data.bucket.SizeBucket.from_files # aspect ratio bucket
      target_area: ---
      num_bucket: 5

previewer:
  _target_: hcpdiff.loggers.preview.ImagePreviewer
  _partial_: True
  infer_cfg: cfgs/infer/t2i_new_vae.yaml

logger:
  - _target_: hcpdiff.loggers.CLILogger
    _partial_: True
    out_path: 'train.log'
    log_step: 20
    enable_log_image: true
    image_log_step: 500
  - _target_: hcpdiff.loggers.TBLogger
    _partial_: True
    out_path: 'tblog/'
    log_step: 5
#  - _target_: hcpdiff.loggers.WanDBLogger
#    _partial_: True
#    out_path: null
#    log_step: 5


