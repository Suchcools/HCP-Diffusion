_base_:
  - cfgs/train/test/base_dataset.yaml
  - cfgs/train/test/train_base.yaml
  - cfgs/train/test/tuning_base.yaml

train:
  train_steps: 20000
  gradient_accumulation_steps: 1
  save_step: 2000


model:
  pretrained_model_name_or_path: 'Lykon/DreamShaper'
  vae_channel: 64
  clip_skip: 1

dataset_dir: data/surtr_dataset'
# if exp_dir is not set, a random time-based directory will be used
# exp_dir: 'exps/surtr'

vae: 
  config: vae/vaegan.yaml
  checkpoint: vae/ckpt/step=13499-model.ckpt


plugin_unet:
  InputAdapter:
    _target_: hcpdiff.models.adapter.InputAdapterPatch
    _partial_: True
    lr: 1e-4
    vae_channel: 64
    layers:
      - 'conv_in'
  OutputAdapter:
    _target_: hcpdiff.models.adapter.OutputAdapterPatch
    _partial_: True
    lr: 1e-4
    vae_channel: 64
    layers:
      - 'conv_out'

data:
  dataset1:
    batch_size: 260
    cache_latents: True

    source:
      data_source1:
        img_root: ${dataset_dir}
        prompt_template: 'prompt_tuning_template/caption.txt'
        caption_file: ${dataset_dir}  # path to image captions (file_words)

    # support images with any size, not recommended for anime training
    # bucket:
    #   _target_: hcpdiff.data.bucket.RatioBucket.from_files # aspect ratio bucket
    #   target_area: ${times:512,512}
    #   num_bucket: 5

    # all images must have the same size, such as 512x704
    bucket:
      _target_: hcpdiff.data.bucket.SizeBucket.from_files # aspect ratio bucket
      target_area: ---
      num_bucket: 5

previewer:
  _target_: hcpdiff.loggers.preview.ImagePreviewer
  _partial_: True
  infer_cfg: cfgs/infer/t2i_new_vae.yaml

logger:
  - _target_: hcpdiff.loggers.CLILogger
    _partial_: True
    out_path: 'train.log'
    log_step: 20
    enable_log_image: true
    image_log_step: 1000
  - _target_: hcpdiff.loggers.TBLogger
    _partial_: True
    out_path: 'tblog/'
    log_step: 5
#  - _target_: hcpdiff.loggers.WanDBLogger
#    _partial_: True
#    out_path: null
#    log_step: 5


